---
layout: post
title: "Deep Learning Resources and References"
date: 2024-03-19 09:00:00 -0500
categories: machine-learning
tags: deep-learning, neural-networks, machine-learning
author: Ryan Angelo
read_time: true
---

A curated collection of Deep Learning resources, from foundational concepts to advanced topics.

## Foundational Courses

[Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by Andrew Ng
A comprehensive series covering neural networks, CNN, RNN, and practical aspects of deep learning projects.

[Fast.ai Course](https://course.fast.ai/)
Practical Deep Learning for Coders - focuses on hands-on implementation using PyTorch.

[MIT 6.S191](http://introtodeeplearning.com/)
MIT's introductory course to deep learning methods with applications.

## Books

[Deep Learning](https://www.deeplearningbook.org/) by Goodfellow, Bengio, and Courville
The comprehensive "bible" of deep learning, covering both theory and practical aspects.

[Dive into Deep Learning](https://d2l.ai/)
An interactive deep learning book with code, math, and discussions.

## Frameworks and Libraries

### PyTorch
- [Official PyTorch Tutorials](https://pytorch.org/tutorials/)
- [PyTorch Lightning](https://www.pytorchlightning.ai/) - Lightweight PyTorch wrapper for high-performance AI research
- [Torchvision](https://pytorch.org/vision/stable/index.html) - Computer vision packages

### TensorFlow
- [TensorFlow Documentation](https://www.tensorflow.org/learn)
- [Keras](https://keras.io/) - High-level neural network library
- [TensorFlow Model Garden](https://github.com/tensorflow/models) - Collection of state-of-the-art models

## Research Papers and Implementations

### Computer Vision
- [ResNet](https://arxiv.org/abs/1512.03385) - Deep Residual Learning
- [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929) - Transformers in Vision
- [YOLO](https://arxiv.org/abs/1506.02640) - Real-Time Object Detection

### Natural Language Processing
- [Transformer](https://arxiv.org/abs/1706.03762) - Attention Is All You Need
- [BERT](https://arxiv.org/abs/1810.04805) - Pre-training of Deep Bidirectional Transformers
- [GPT](https://arxiv.org/abs/2005.14165) - Language Models are Few-Shot Learners

## Practical Resources

### Datasets
- [Papers with Code Datasets](https://paperswithcode.com/datasets)
- [Google Dataset Search](https://datasetsearch.research.google.com/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)

### Model Zoo
- [PyTorch Hub](https://pytorch.org/hub/)
- [TensorFlow Hub](https://tfhub.dev/)
- [Hugging Face Models](https://huggingface.co/models)

## Advanced Topics

### Optimization and Training
- [Learning Rate Scheduling](https://arxiv.org/abs/1506.01186)
- [Batch Normalization](https://arxiv.org/abs/1502.03167)
- [Dropout](https://jmlr.org/papers/v15/srivastava14a.html)

### Architecture Design
- [Neural Architecture Search](https://arxiv.org/abs/1611.01578)
- [Network Pruning](https://arxiv.org/abs/1510.00149)
- [Knowledge Distillation](https://arxiv.org/abs/1503.02531)

## Community and News

- [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)
- [Papers with Code](https://paperswithcode.com/)
- [Distill.pub](https://distill.pub/) - Clear explanations of machine learning concepts
- [ML Subreddit](https://www.reddit.com/r/MachineLearning/)